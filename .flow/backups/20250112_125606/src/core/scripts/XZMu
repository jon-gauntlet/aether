#!/bin/bash

# Context Crystallizer
# Manages context optimization and inheritance across sessions

set -eo pipefail

# Configuration
CURSOR_CONFIG_DIR="${CURSOR_CONFIG_DIR:-$HOME/.config/cursor}"
CURSOR_STATE_DIR="${CURSOR_STATE_DIR:-$HOME/.local/state/cursor}"
CURSOR_DATA_DIR="${CURSOR_DATA_DIR:-$HOME/.local/share/cursor}"

# Paths
CONTEXTS_DIR="$CURSOR_CONFIG_DIR/contexts"
ACTIVE_CONTEXT="$CURSOR_STATE_DIR/active_context.json"
CONTEXT_HISTORY="$CURSOR_STATE_DIR/context_history.jsonl"
CRYSTALLIZED_DIR="$CURSOR_DATA_DIR/crystallized"
MEMORY_STATS="$CURSOR_STATE_DIR/memory_stats.json"

# Performance Settings
MAX_CONTEXT_SIZE=50000  # bytes
OPTIMIZATION_THRESHOLD=0.75  # trigger at 75% of max
CRYSTAL_RETENTION_DAYS=7
CHECK_INTERVAL=5  # seconds
MEMORY_CHECK_INTERVAL=60  # seconds

# Ensure directories exist
mkdir -p "$CURSOR_STATE_DIR" "$CRYSTALLIZED_DIR"
mkdir -p "$CONTEXTS_DIR"/{system,general,projects,sacred,gauntlet}

# Initialize memory stats if needed
if [[ ! -f "$MEMORY_STATS" ]]; then
    echo '{"total_processed": 0, "optimizations": 0, "last_check": 0}' > "$MEMORY_STATS"
fi

# Helper Functions
log() {
    echo "[$(date -Iseconds)] $*" >&2
}

update_memory_stats() {
    local stat_type=$1
    local value=$2
    local temp_file=$(mktemp)
    
    jq --arg type "$stat_type" \
       --arg value "$value" \
       --arg now "$(date +%s)" \
       '.[$type] = ($value | tonumber) | .last_check = ($now | tonumber)' \
       "$MEMORY_STATS" > "$temp_file"
    
    mv "$temp_file" "$MEMORY_STATS"
}

check_memory_pressure() {
    local pressure=$(cat /proc/pressure/memory | grep "some" | awk '{print $2}' | cut -d= -f2)
    if (( $(echo "$pressure > 60" | bc -l) )); then
        log "High memory pressure detected ($pressure). Triggering optimization."
        return 0
    fi
    return 1
}

optimize_context() {
    local context_data=$1
    local max_size=${2:-$MAX_CONTEXT_SIZE}
    
    # Use jq streaming for large files
    jq -c --arg max "$max_size" '
    def score(obj):
        # Base importance
        (obj.importance // 0) * 2 +
        (obj.frequency // 0) * 1.5 +
        (obj.recent // 0) * 3 +
        # Essence hierarchy weights
        (if obj.type == "sacred" then 100
         elif obj.type == "general" then 50
         elif obj.type == "project" then 25
         else 0 end) +
        # Special protection for Orthodox wisdom
        (if obj.source == "orthodox" then 200 else 0 end) +
        # Principle protection
        (if obj.category == "principle" then 75
         elif obj.category == "pattern" then 40
         elif obj.category == "wisdom" then 60
         else 0 end);
    
    def optimize_array(arr):
        arr | sort_by(score(.)) | reverse |
        while(
            (. | tojson | length) > ($max | tonumber);
            # Never remove sacred content
            map(select(.type == "sacred" or .source == "orthodox")) + 
            (map(select(.type != "sacred" and .source != "orthodox")) | .[0:-1])
        );
    
    {
        concepts: optimize_array(.concepts),
        state: (.state | with_entries(
            select(
                .value.type == "sacred" or
                .value.source == "orthodox" or
                .value.priority > 0.7
            )
        )),
        patterns: optimize_array(.patterns),
        principles: (.principles // []),  # Never optimize principles
        metrics: .metrics,
        optimized_at: now
    }' <<<"$context_data"
}

crystallize_context() {
    local context_data=$1
    local context_type=$2
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local crystal_file="$CRYSTALLIZED_DIR/${context_type}_${timestamp}.json"
    
    # Extract essential information using jq streaming
    jq -c '{
        timestamp: now,
        type: $type,
        essence: {
            key_concepts: (.concepts | sort_by(.importance) | reverse | .[0:5]),
            critical_state: (.state | to_entries | sort_by(.value.priority) | reverse | .[0:3]),
            learned_patterns: (.patterns | sort_by(.frequency) | reverse | .[0:5]),
            active_principles: (.principles // [])  # Preserve all principles
        },
        metrics: {
            context_size: (.size // 0),
            interaction_count: (.interactions // 0),
            success_rate: (.success_rate // 0)
        }
    }' --arg type "$context_type" <<<"$context_data" > "$crystal_file"
    
    echo "$crystal_file"
}

merge_crystals() {
    local type=$1
    local max_age=${2:-3600}
    local cutoff=$(( $(date +%s) - max_age ))
    
    # Use parallel processing for multiple crystals
    find "$CRYSTALLIZED_DIR" -name "${type}_*.json" -type f -newermt "@$cutoff" -print0 |
    xargs -0 cat 2>/dev/null |
    jq -s 'reduce .[] as $item (
        {};
        .timestamp = now |
        .type = $item.type |
        .essence.key_concepts = ((.essence.key_concepts // []) + $item.essence.key_concepts | unique) |
        .essence.critical_state = ((.essence.critical_state // []) + $item.essence.critical_state | unique) |
        .essence.learned_patterns = ((.essence.learned_patterns // []) + $item.essence.learned_patterns | unique) |
        .metrics = {
            context_size: ((.metrics.context_size + $item.metrics.context_size) / 2),
            interaction_count: (.metrics.interaction_count + $item.metrics.interaction_count),
            success_rate: ((.metrics.success_rate + $item.metrics.success_rate) / 2)
        }
    )'
}

cleanup_old_crystals() {
    # Keep crystals for configured days
    find "$CRYSTALLIZED_DIR" -name "*.json" -type f -mtime "+$CRYSTAL_RETENTION_DAYS" -delete
}

check_principle_integrity() {
    log "Checking principle integrity..."
    
    # Check sacred principles
    local sacred_dir="$CONTEXTS_DIR/sacred"
    for principle in "$sacred_dir"/**/*.md; do
        if [[ -f "$principle" ]]; then
            # Create backup if none exists
            local backup="$CURSOR_DATA_DIR/backups/sacred/$(basename "$principle")"
            if [[ ! -f "$backup" ]]; then
                mkdir -p "$(dirname "$backup")"
                cp "$principle" "$backup"
                log "Created backup of sacred principle: $(basename "$principle")"
            fi
            
            # Verify content integrity
            if ! diff -q "$principle" "$backup" >/dev/null 2>&1; then
                log "WARNING: Sacred principle modified: $(basename "$principle")"
                log "Restoring from backup..."
                cp "$backup" "$principle"
            fi
        fi
    done
    
    # Check general principles
    local general_dir="$CONTEXTS_DIR/general/principles"
    if [[ ! -d "$general_dir" ]]; then
        mkdir -p "$general_dir"
    fi
    
    # Verify essential principles exist
    local essential_principles=("purification" "growth_balance" "simplicity")
    for principle in "${essential_principles[@]}"; do
        if [[ ! -f "$general_dir/${principle}.md" ]]; then
            log "WARNING: Missing essential principle: ${principle}"
        fi
    done
    
    # Check project principles
    local projects_dir="$CONTEXTS_DIR/projects"
    for project in "$projects_dir"/*; do
        if [[ -d "$project" ]]; then
            local essence_dir="$project/essence"
            if [[ ! -d "$essence_dir" ]]; then
                mkdir -p "$essence_dir"
                log "Created essence directory for project: $(basename "$project")"
            fi
        fi
    done
}

crystallize_pattern_source() {
    local source_file=$1
    local source_type=$2
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local crystal_file="$CONTEXTS_DIR/patterns/crystals/${source_type}_${timestamp}.json"
    
    # Extract key patterns and insights
    jq -n --arg source "$(cat "$source_file")" --arg type "$source_type" '{
        timestamp: now,
        type: $type,
        source_file: $source,
        patterns: {
            key_insights: [],  # To be populated by Cursor/Claude
            core_patterns: [], # To be populated by Cursor/Claude
            applications: [],  # To be populated by Cursor/Claude
            integrations: []   # To be populated by Cursor/Claude
        },
        metadata: {
            last_crystallized: now,
            crystallization_count: 1,
            integration_points: []
        }
    }' > "$crystal_file"
    
    echo "$crystal_file"
}

integrate_pattern_crystal() {
    local crystal_file=$1
    local context_type=$2
    
    # Create integration points in active context
    jq -s '.[0] * {
        patterns: (.[0].patterns + .[1].patterns.core_patterns),
        integrations: (.[0].integrations // []) + [{
            type: "pattern_crystal",
            source: .[1].source_file,
            timestamp: now,
            patterns: .[1].patterns.key_insights
        }]
    }' "$ACTIVE_CONTEXT" "$crystal_file" > "${ACTIVE_CONTEXT}.tmp"
    
    mv "${ACTIVE_CONTEXT}.tmp" "$ACTIVE_CONTEXT"
}

check_pattern_sources() {
    log "Checking pattern sources..."
    
    # Ensure pattern directories exist
    local patterns_dir="$CONTEXTS_DIR/patterns"
    mkdir -p "$patterns_dir"/{sources,crystals,integrations}
    
    # Check for new pattern sources
    for source in "$patterns_dir/sources"/*; do
        if [[ -f "$source" ]]; then
            local source_type=$(basename "$source" | cut -d. -f1)
            local latest_crystal=$(find "$patterns_dir/crystals" -name "${source_type}_*.json" -type f -printf '%T@ %p\n' | sort -nr | head -1 | cut -d' ' -f2-)
            
            if [[ -z "$latest_crystal" ]] || ! diff -q "$source" <(jq -r '.source_file' "$latest_crystal") >/dev/null 2>&1; then
                log "New or modified pattern source detected: $(basename "$source")"
                local crystal_file=$(crystallize_pattern_source "$source" "$source_type")
                log "Created pattern crystal: $(basename "$crystal_file")"
                
                # Integrate with active context if exists
                if [[ -f "$ACTIVE_CONTEXT" ]]; then
                    integrate_pattern_crystal "$crystal_file" "general"
                    log "Integrated pattern crystal into active context"
                fi
            fi
        fi
    done
}

# Main loop
trap cleanup_old_crystals EXIT

# Initialize if needed
if [[ ! -f "$ACTIVE_CONTEXT" ]]; then
    echo '{"timestamp": 0, "type": "general"}' > "$ACTIVE_CONTEXT"
fi

if [[ ! -f "$CONTEXT_HISTORY" ]]; then
    touch "$CONTEXT_HISTORY"
fi

check_principle_integrity

watch_context_changes() {
    local last_size=0
    local last_memory_check=0
    local last_principle_check=0
    local PRINCIPLE_CHECK_INTERVAL=3600  # Check principles hourly
    local PATTERN_CHECK_INTERVAL=1800  # Check patterns every 30 minutes
    local last_pattern_check=0
    
    while true; do
        current_time=$(date +%s)
        
        # Check memory pressure periodically
        if (( current_time - last_memory_check >= MEMORY_CHECK_INTERVAL )); then
            if check_memory_pressure; then
                if [[ -f "$ACTIVE_CONTEXT" ]]; then
                    log "Optimizing due to memory pressure"
                    local context_data=$(cat "$ACTIVE_CONTEXT")
                    local optimized_data=$(optimize_context "$context_data" $(( MAX_CONTEXT_SIZE * 3 / 4 )))
                    echo "$optimized_data" > "$ACTIVE_CONTEXT"
                    update_memory_stats "optimizations" "$(( $(jq '.optimizations' "$MEMORY_STATS") + 1 ))"
                fi
            fi
            last_memory_check=$current_time
        fi
        
        # Periodic principle integrity check
        if (( current_time - last_principle_check >= PRINCIPLE_CHECK_INTERVAL )); then
            check_principle_integrity
            last_principle_check=$current_time
        fi
        
        # Pattern source check
        if (( current_time - last_pattern_check >= PATTERN_CHECK_INTERVAL )); then
            check_pattern_sources
            last_pattern_check=$current_time
        fi
        
        if [[ -f "$ACTIVE_CONTEXT" ]]; then
            current_size=$(stat -f%z "$ACTIVE_CONTEXT" 2>/dev/null || stat -c%s "$ACTIVE_CONTEXT")
            
            # Check if optimization is needed
            if (( current_size > last_size + (last_size / 2) )) || (( current_size > MAX_CONTEXT_SIZE * 3 / 4 )); then
                log "Context size threshold reached ($current_size bytes). Crystallizing..."
                
                # Read and crystallize current context
                local context_data=$(cat "$ACTIVE_CONTEXT")
                local context_type=$(jq -r '.type // "general"' <<<"$context_data")
                
                # Optimize current context
                local optimized_data=$(optimize_context "$context_data")
                echo "$optimized_data" > "$ACTIVE_CONTEXT"
                
                # Create new crystal
                local crystal_file=$(crystallize_context "$context_data" "$context_type")
                log "Created crystal: $crystal_file"
                
                # Merge recent crystals
                local merged_data=$(merge_crystals "$context_type")
                if [[ -n "$merged_data" ]]; then
                    echo "$merged_data" > "$CRYSTALLIZED_DIR/${context_type}_merged.json"
                    log "Updated merged crystal for type: $context_type"
                fi
                
                last_size=$(stat -f%z "$ACTIVE_CONTEXT" 2>/dev/null || stat -c%s "$ACTIVE_CONTEXT")
                update_memory_stats "total_processed" "$(( $(jq '.total_processed' "$MEMORY_STATS") + current_size ))"
            fi
        fi
        
        sleep "$CHECK_INTERVAL"
    done
}

watch_context_changes 