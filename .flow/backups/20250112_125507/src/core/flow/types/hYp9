#!/bin/bash

set -euo pipefail

# Environment setup
CURSOR_CONFIG_DIR="${CURSOR_CONFIG_DIR:-$HOME/.config/cursor}"
CURSOR_STATE_DIR="${CURSOR_STATE_DIR:-$HOME/.local/state/cursor}"
CURSOR_DATA_DIR="${CURSOR_DATA_DIR:-$HOME/.local/share/cursor}"
GAUNTLET_DATA_DIR="${GAUNTLET_DATA_DIR:-$HOME/.local/share/gauntlet}"
AI_MODELS_DIR="${AI_MODELS_DIR:-$HOME/.local/share/cursor/models}"
CONTEXT_DIR="${CONTEXT_DIR:-$HOME/.local/share/cursor/contexts}"

# Initialize required directories and files
init_gauntlet_dirs() {
    mkdir -p "$GAUNTLET_DATA_DIR/"{stats,metrics,state,ai}
    mkdir -p "$GAUNTLET_DATA_DIR/ai/"{models,contexts,predictions}
    
    # Initialize stats file if needed
    local stats_file="$GAUNTLET_DATA_DIR/stats/daily_stats.json"
    if [[ ! -f "$stats_file" ]]; then
        echo "{}" > "$stats_file"
    fi
    
    # Initialize focus metrics file if needed
    local focus_file="$GAUNTLET_DATA_DIR/state/focus_metrics.json"
    if [[ ! -f "$focus_file" ]]; then
        echo '{
            "deep_mode_duration": 0,
            "flow_state_duration": 0,
            "focus_sessions": 0
        }' > "$focus_file"
    fi

    # Initialize AI metrics file if needed
    local ai_metrics_file="$GAUNTLET_DATA_DIR/ai/metrics.json"
    if [[ ! -f "$ai_metrics_file" ]]; then
        echo '{
            "model_memory_usage": 0,
            "context_load_times": [],
            "inference_latency": [],
            "context_quality_score": 0,
            "active_models": [],
            "context_size": 0
        }' > "$ai_metrics_file"
    fi
}

# Logging function
log() {
    echo "[$(date -Iseconds)] $*"
}

# Notify systemd watchdog
notify_watchdog() {
    echo "WATCHDOG=1"
}

# Ensure numeric values
ensure_numeric() {
    local value="${1:-0}"
    if [[ "$value" =~ ^[0-9]+\.?[0-9]*$ ]]; then
        echo "$value"
    else
        echo "0"
    fi
}

# Calculate percentage
calc_percentage() {
    local used="${1:-0}"
    local total="${2:-100}"
    if ((total > 0)); then
        printf "%.2f" "$(echo "scale=2; $used * 100 / $total" | bc)"
    else
        echo "0"
    fi
}

# Get JSON value with default
get_json_value() {
    local file="$1"
    local key="$2"
    local default="$3"
    
    if [[ -f "$file" ]]; then
        local value
        value=$(jq -r ".$key // $default" "$file" 2>/dev/null)
        if [[ $? -eq 0 && "$value" != "null" ]]; then
            echo "$value"
            return 0
        fi
    fi
    echo "$default"
}

# Get AI metrics
get_ai_metrics() {
    local ai_metrics_file="$GAUNTLET_DATA_DIR/ai/metrics.json"
    local model_mem=0
    local context_size=0
    local quality_score=0

    # Calculate model memory usage
    if [[ -d "$AI_MODELS_DIR" ]]; then
        model_mem=$(du -sb "$AI_MODELS_DIR" 2>/dev/null | cut -f1 || echo "0")
    fi

    # Calculate context size
    if [[ -d "$CONTEXT_DIR" ]]; then
        context_size=$(du -sb "$CONTEXT_DIR" 2>/dev/null | cut -f1 || echo "0")
    fi

    # Calculate context quality score (placeholder for AI-based scoring)
    quality_score=$(get_json_value "$ai_metrics_file" "context_quality_score" "0")

    # Get active models
    local active_models="[]"
    if [[ -d "$AI_MODELS_DIR" ]]; then
        active_models=$(find "$AI_MODELS_DIR" -type f -name "*.bin" -exec basename {} \; | jq -R -s -c 'split("\n")[:-1]')
    fi

    # Create AI metrics JSON
    jq -n \
        --arg mem "$model_mem" \
        --arg size "$context_size" \
        --arg score "$quality_score" \
        --argjson models "$active_models" \
        '{
            "model_memory_usage": ($mem | tonumber),
            "context_size": ($size | tonumber),
            "context_quality_score": ($score | tonumber),
            "active_models": $models
        }'
}

# Create enhanced JSON metrics
create_json_metrics() {
    local cpu_usage="$1"
    local mem_usage="$2"
    local swap_usage="$3"
    local disk_usage="$4"
    local current_stats="$5"
    local focus_metrics_file="$6"
    local ai_metrics="$7"
    
    # Get focus metrics with defaults
    local deep_mode=$(get_json_value "$focus_metrics_file" "deep_mode_duration" "0")
    local flow_state=$(get_json_value "$focus_metrics_file" "flow_state_duration" "0")
    local focus_sessions=$(get_json_value "$focus_metrics_file" "focus_sessions" "0")
    
    # Debug logging
    log "CPU Usage: $cpu_usage"
    log "Memory Usage: $mem_usage"
    log "Swap Usage: $swap_usage"
    log "Disk Usage: $disk_usage"
    log "Current Stats: $current_stats"
    log "Deep Mode: $deep_mode"
    log "Flow State: $flow_state"
    log "Focus Sessions: $focus_sessions"
    log "AI Metrics: $ai_metrics"
    
    # Ensure current_stats is valid JSON
    if ! echo "$current_stats" | jq . >/dev/null 2>&1; then
        log "Invalid current_stats JSON, using empty object"
        current_stats="{}"
    fi
    
    # Create base metrics object
    local metrics_json
    metrics_json=$(jq -n \
        --arg timestamp "$(date -Iseconds)" \
        --argjson stats "$current_stats" \
        --arg cpu "$cpu_usage" \
        --arg mem "$mem_usage" \
        --arg swap "$swap_usage" \
        --arg disk "$disk_usage" \
        --arg deep "$deep_mode" \
        --arg flow "$flow_state" \
        --arg focus "$focus_sessions" \
        --argjson ai "$ai_metrics" \
        '{
            timestamp: $timestamp,
            daily_stats: $stats,
            system_metrics: {
                cpu_usage: ($cpu | tonumber),
                memory_usage: ($mem | tonumber),
                swap_usage: ($swap | tonumber),
                disk_usage: ($disk | tonumber)
            },
            focus_metrics: {
                deep_mode_duration: ($deep | tonumber),
                flow_state_duration: ($flow | tonumber),
                focus_sessions: ($focus | tonumber)
            },
            ai_metrics: $ai
        }' 2>/dev/null) || {
            log "Failed to create metrics JSON: $metrics_json"
            return 1
        }
    
    # Output the formatted JSON
    if [[ -n "$metrics_json" ]]; then
        echo "$metrics_json"
        return 0
    else
        log "Empty metrics JSON generated"
        return 1
    fi
}

# Predict resource needs
predict_resource_needs() {
    local metrics_file="$1"
    local predictions_file="$GAUNTLET_DATA_DIR/ai/predictions/$(date +%Y%m%d).json"
    
    # Simple prediction based on current metrics (placeholder for AI-based prediction)
    local mem_usage=$(jq -r '.system_metrics.memory_usage' "$metrics_file")
    local cpu_usage=$(jq -r '.system_metrics.cpu_usage' "$metrics_file")
    local ai_mem=$(jq -r '.ai_metrics.model_memory_usage' "$metrics_file")
    
    # Calculate predicted needs (placeholder logic)
    local pred_mem=$(echo "$mem_usage * 1.2" | bc)
    local pred_cpu=$(echo "$cpu_usage * 1.1" | bc)
    local pred_ai_mem=$(echo "$ai_mem * 1.3" | bc)
    
    # Create predictions JSON
    jq -n \
        --arg mem "$pred_mem" \
        --arg cpu "$pred_cpu" \
        --arg ai_mem "$pred_ai_mem" \
        '{
            timestamp: now | tostring,
            predicted_memory: ($mem | tonumber),
            predicted_cpu: ($cpu | tonumber),
            predicted_ai_memory: ($ai_mem | tonumber)
        }' > "$predictions_file"
}

# Optimize gauntlet performance with AI integration
optimize_gauntlet() {
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local stats_file="$GAUNTLET_DATA_DIR/stats/daily_stats.json"
    local metrics_file="$GAUNTLET_DATA_DIR/metrics/optimization_${timestamp}.json"
    local focus_metrics_file="$GAUNTLET_DATA_DIR/state/focus_metrics.json"
    local temp_file=$(mktemp)
    
    # Ensure stats file exists with valid JSON
    if [[ ! -f "$stats_file" ]]; then
        echo "{}" > "$stats_file"
    fi
    
    # Get today's date
    local today=$(date +%Y-%m-%d)
    
    # Read current stats
    local current_stats
    if ! current_stats=$(jq -r ".[\"$today\"] // {}" "$stats_file" 2>/dev/null); then
        current_stats="{}"
    fi
    
    # Get system metrics safely
    local cpu_usage=$(ensure_numeric "$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' || echo "0")")
    local mem_total=$(ensure_numeric "$(free | grep Mem | awk '{print $2}')")
    local mem_used=$(ensure_numeric "$(free | grep Mem | awk '{print $3}')")
    local swap_total=$(ensure_numeric "$(free | grep Swap | awk '{print $2}')")
    local swap_used=$(ensure_numeric "$(free | grep Swap | awk '{print $3}')")
    local disk_usage=$(ensure_numeric "$(df -h / | tail -1 | awk '{print $5}' | tr -d '%' || echo "0")")
    
    local mem_usage=$(ensure_numeric "$(calc_percentage "$mem_used" "$mem_total")")
    local swap_usage=$(ensure_numeric "$(calc_percentage "$swap_used" "$swap_total")")
    
    # Get AI metrics
    local ai_metrics
    ai_metrics=$(get_ai_metrics)
    
    # Debug logging
    log "Creating metrics with:"
    log "CPU Usage: $cpu_usage"
    log "Memory Usage: $mem_usage"
    log "Swap Usage: $swap_usage"
    log "Disk Usage: $disk_usage"
    log "Current Stats: $current_stats"
    log "AI Metrics: $ai_metrics"
    
    # Create metrics JSON with AI integration
    if ! create_json_metrics "$cpu_usage" "$mem_usage" "$swap_usage" "$disk_usage" "$current_stats" "$focus_metrics_file" "$ai_metrics" > "$temp_file" 2>/dev/null; then
        log "Error: Failed to create JSON metrics"
        rm -f "$temp_file"
        return 1
    fi

    # Validate JSON
    if ! jq . "$temp_file" >/dev/null 2>&1; then
        log "Error: Invalid JSON generated"
        cat "$temp_file" | jq . 2>&1 | log
        rm -f "$temp_file"
        return 1
    fi

    # Move JSON to final location
    mv "$temp_file" "$metrics_file"
    log "Optimized gauntlet metrics to $metrics_file"

    # Predict future resource needs
    predict_resource_needs "$metrics_file"

    # Apply AI-aware optimizations based on metrics
    if [[ $(jq -r '.system_metrics.memory_usage' "$metrics_file") -gt 80 ]]; then
        log "High memory usage detected, triggering cleanup"
        find "$GAUNTLET_DATA_DIR/stats" -type f -name "*.json" -mtime +7 -delete
        
        # Reduce AI model memory if needed
        if [[ $(jq -r '.ai_metrics.model_memory_usage' "$metrics_file") -gt 3000000000 ]]; then
            log "High AI model memory usage, cleaning unused models"
            find "$AI_MODELS_DIR" -type f -atime +30 -delete
        fi
    fi

    if [[ $(jq -r '.system_metrics.swap_usage' "$metrics_file") -gt 50 ]]; then
        log "High swap usage detected, adjusting memory limits"
        systemctl --user set-property cursor-context.slice MemoryHigh=2G
        
        # Adjust AI model memory limits
        if [[ $(jq -r '.ai_metrics.model_memory_usage' "$metrics_file") -gt 2000000000 ]]; then
            log "Reducing AI model memory limits"
            systemctl --user set-property cursor-ai.slice MemoryHigh=3G
        fi
    fi

    # Optimize based on focus metrics
    local flow_duration=$(jq -r '.focus_metrics.flow_state_duration' "$metrics_file")
    if [[ $(echo "$flow_duration > 3600" | bc -l) -eq 1 ]]; then
        log "Extended flow state detected, optimizing for AI context preservation"
        systemctl --user set-property cursor-context.slice CPUWeight=120
        systemctl --user set-property cursor-ai.slice CPUWeight=150
    fi
}

# Main loop
init_gauntlet_dirs  # Initialize directories first
while true; do
    if optimize_gauntlet; then
        notify_watchdog
    else
        log "Failed to optimize gauntlet metrics"
    fi
    sleep 300  # Run every 5 minutes
done 